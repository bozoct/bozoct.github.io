<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Bo Zhang</title>

    <meta name="author" content="Bo Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Bo Zhang
                </p>
                <p>
                  Hello! I am Bo Zhang (张博).
                  I'm now a research engineer at <a href="https://www.lixiang.com/">Li Auto</a> in Shanghai, where I work on camera and vision.
                  I did my PhD at <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, where I was advised by <a href="https://www.au.tsinghua.edu.cn/info/1225/2315.htm">Jinli Suo</a>.
                  I obtained my bachelor's degree from the Department of Precision Instruments, Tsinghua University.
                </p>
                <p style="text-align:center">
                  <a href="mailto:bzhang.thu@gmail.com">Email</a> &nbsp;/&nbsp;
                  <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=QgKuBj4AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/bozoct/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="myimages/profile.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="myimages/profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, computational imaging, image processing and deep learning.
                  I am familiar with optics, camera and image processing algorithms.
                  My research is about developing optical systems and algorithms to enhance imaging quality for human vision and applications.
                  Previous projects involve low-light enhancement/object detection, snapshot compressive imaging and event camera vision.
                  <!-- <span class="highlight">highlighted</span>. -->
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

<tr onmouseout="esci_stop()" onmouseover="esci_start()">
  <td style="padding:16px;width:20%;vertical-align:middle">
    <div class="one">
      <div class="two" id='radmesh_image'>
        <img src='images/radmesh_after.jpg' width=100%>
      </div>
      <img src='images/radmesh_before.jpg' width=100%>
    </div>
    <script type="text/javascript">
      function radmesh_start() {
        document.getElementById('radmesh_image').style.opacity = "1";
      }

      function radmesh_stop() {
        document.getElementById('radmesh_image').style.opacity = "0";
      }
      radmesh_stop()
    </script>
  </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <a href="https://ieeexplore.ieee.org/abstract/document/10750378">
      <span class="papertitle">Event-Enhanced Snapshot Compressive Videography at 10K FPS</span>
    </a>
    <br>
    <strong>Bo Zhang</strong>,
    <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
    <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
    <br>
    <em>TPAMI</em>, 2024
    <br>
    <!-- <a href="https://half-potato.gitlab.io/rm/">project page</a>
    /
    <a href="https://arxiv.org/abs/2512.04076">arXiv</a> -->
    <p></p>
    <p>
      Integrating an event camera into snapshot compressive imaging and realizing 10K FPS imaging with a snapshot measurement and sparse events.
    </p>
  </td>
</tr>

<tr onmouseout="esketch_stop()" onmouseover="esketch_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/nexf_after.jpg' width=100%>
					</div>
          <img src='images/nexf_before.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/abstract/document/10536615">
          <span class="papertitle">Real-Time Sketching of Harshly Lit Driving Environment Perception by Neuromorphic Sensing</span>
        </a>
        <br>
        Yuqi Han,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <strong>Bo Zhang</strong>,
        Jiachen Zhao,
        Yuxiao Cheng,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>TIV</em>, 2024
        <br>
        <a href="https://m-niemeyer.github.io/nexf/">project page</a>
        /
        <a href="https://arxiv.org/abs/2510.08279">arXiv</a>
        <p></p>
        <p>
		Learning a neural field that optimizes exposure for each 3D point enables high-quality 3D-consistent view synthesis despite extreme exposure variation during capture.
        </p>
      </td>
    </tr>
	
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://www.nature.com/articles/s41598-024-57333-2">
          <span class="papertitle">An event-oriented diffusion-refinement method for sparse events completion</span>
        </a>
        <br>
		    <strong>Bo Zhang</strong>,
        Yuqi Han,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>Scientific Reports</em>, 2024
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
          Developing a diffusion model that completes sparse events with high fidelity to enable human observation and dowstream applications.
        </p>
      </td>
    </tr>

    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S1566253523001380">
			<span class="papertitle">A complementary dual-backbone transformer extracting and fusing weak cues for object detection in extremely dark videos</span>
        </a>
        <br>
				<strong>Bo Zhang</strong>,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
				<br>
        <em>Information Fusion</em>, 2024
        <!-- &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
          Developing a dual-backbone Transformer for accurate video object detection in low-light scenarios.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
      <!-- bgcolor="#ffffd0" -->
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">DarkVision: a benchmark for low-light image/video perception</span>
        </a>
        <br>
				<strong>Bo Zhang</strong>,
        Yuchen Guo,
        Runzhao Yang,
        Zhihong Zhang,
        Jiayi Xie,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>CVM</em>, 2025
        <!-- &nbsp <font color="red"><strong>(Oral Presentation)</strong></font> -->
        <br>
        <a href="https://cat-4d.github.io/">Dataset to be released soon</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
          Building a large-scale benchmark for low-light image and video perception, including enhancement and object detection.
        </p>
      </td>
    </tr>


    <tr onmouseout="r2r_stop()" onmouseover="r2r_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='r2r_image'><video  width=100% muted autoplay loop>
          <source src="images/r2r.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/r2r.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function r2r_start() {
            document.getElementById('r2r_image').style.opacity = "1";
          }

          function r2r_stop() {
            document.getElementById('r2r_image').style.opacity = "0";
          }
          r2r_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://link.springer.com/article/10.1186/s43074-022-00065-1">
          <span class="papertitle">From compressive sampling to compressive tasking: retrieving semantics in compressed domain with low bandwidth</span>
        </a>
        <br>
        Zhihong Zhang,
				<strong>Bo Zhang</strong>, 
        <a href="https://jbhuang0604.github.io/">Xin Yuan</a>,
        Siming Zheng,
        Xiongfei Su,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        David J. Brady,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>PhotoniX</em>, 2022
        <br>
        <a href="https://relight-to-reconstruct.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.15211">arXiv</a>
        <p></p>
        <p>
          A survey for semantic tasks in comressed domain.
        </p>
      </td>
    </tr>


    <tr onmouseout="simvs_stop()" onmouseover="simvs_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='simvs_image'><video  width=100% muted autoplay loop>
          <source src="images/simvs.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/simvs.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function simvs_start() {
            document.getElementById('simvs_image').style.opacity = "1";
          }

          function simvs_stop() {
            document.getElementById('simvs_image').style.opacity = "0";
          }
          simvs_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://alextrevithick.github.io/simvs/">
          <span class="papertitle">Snapshot compressive imaging based digital image correlation: temporally super-resolved full-resolution deformation measurement</span>
        </a>
        <br>
        Wenwu Chen,
        <strong>Bo Zhang</strong>,
        Liuning Gu,
        Haibo Liu,
        <a href="https://www.au.tsinghua.edu.cn/info/1225/2315.htm">Jinli Suo</a>,
        Xinxing Shao
        <br>
        <em>Optics Express</em>, 2022
        <br>
        <a href="https://alextrevithick.github.io/simvs/">project page</a>
        /
        <a href="https://arxiv.org/abs/2412.07696">arXiv</a>
        <p></p>
        <p>
          SCI meets DIC.
        </p>
      </td>
    </tr>


    <tr onmouseout="power_stop()" onmouseover="power_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='power_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/power.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/power.png' width="160">
        </div>
        <script type="text/javascript">
          function power_start() {
            document.getElementById('power_image').style.opacity = "1";
          }

          function power_stop() {
            document.getElementById('power_image').style.opacity = "0";
          }
          power_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://link.springer.com/chapter/10.1007/978-981-19-6613-2_653">
			<span class="papertitle">NeRFE: Free View Synthesis for Event Data</span>
        </a>
        <br>
				<strong>Bo Zhang</strong>,
        Yuqi Han,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>International Conference on Guidance, Navigation and Control</em>, 2022
        <br>
        <a href="https://x.com/jon_barron/status/1891918200931061996">tweet</a>
        /
        <a href="https://arxiv.org/abs/2502.10647">arXiv</a>
        <p></p>
        <p>
          Developing a neural radiance field method for event cameras to enable high-quality view synthesis.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat3d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat3d_start() {
            document.getElementById('cat3d_image').style.opacity = "1";
          }

          function cat3d_stop() {
            document.getElementById('cat3d_image').style.opacity = "0";
          }
          cat3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://opg.optica.org/optica/fulltext.cfm?uri=optica-9-4-451">
			<span class="papertitle">End-to-end snapshot compressed super-resolution imaging with deep optics
</span>
        </a>
        <br>
        <strong>Bo Zhang</strong>,
				<a href="https://ruiqigao.github.io/">Xin Yuan</a>*,
        Chao Deng,
        Zhihong Zhang,
        <a href="https://scholar.google.com/citations?user=e4lel8QAAAAJ&hl=en">Jinli Suo</a>,
        <a href="https://scholar.google.com/citations?user=CHAajY4AAAAJ&hl=en">Qionghai Dai</a>
        <br>
        <em>Optica</em>, 2022
        <br>
        <a href="https://cat3d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
        <p></p>
        <p>
          Integrating deep optics into snapshot compressive imaging to achieve high-quality super-resolution imaging from a single snapshot measurement. 
        </p>
      </td>
    </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #fcb97d;">
								 <h2>Micropapers</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>


            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #aaba9e;">
								 <h2>Recorded Talks</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://www.youtube.com/watch?v=hFlF33JZbA0">Radiance Fields and the Future of Generative Media, 2025</a><br>				  
                <a href="https://www.youtube.com/watch?v=h9vq_65eDas">View Dependent Podcast, 2024</a><br>
                <a href="https://www.youtube.com/watch?v=4tDhYsFuEqo">Bay Area Robotics Symposium, 2023
</a><br>
                <a href="https://youtu.be/TvWkwDYtBP4?t=7604">EGSR Keynote, 2021</a><br>
				<a href="https://www.youtube.com/watch?v=nRyOzHpcr4Q">TUM AI Lecture Series, 2020</a><br>
				<a href="https://www.youtube.com/watch?v=HfJpQCBTqZs">Vision & Graphics Seminar at MIT, 2020</a>
              </td>
            </tr>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="https://iccv.thecvf.com/">Lead Area Chair, ICCV 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2025/Organizers">Lead Area Chair, CVPR 2025</a>
                <br>
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
